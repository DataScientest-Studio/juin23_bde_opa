== Project development and deployment

The project has been developed following principles that make for easy iterative development and deployment.

It is split into 3 main sub-parts that run independently from each other, following a philosophy akin to micro-services :

* the financial data reader (which reads data from the external API and saves it into the database)
* the HTTP API (which reads data from the database and makes it available to other components)
* the dashboard (which reads from the API and presents it via a graphical UI)

=== Software development

The code is versioned-controlled using `git`, with a central repository available on GitHubfootnote:[https://github.com/DataScientest-Studio/juin23_bde_opa]. As of the writing of the report section, the `main` branch has over 200 commits with meaningful messages. GitHub issuesfootnote:[https://github.com/DataScientest-Studio/juin23_bde_opa/issues] have been used.

[#commit-log]
.Commit log of the project (as of 18/09/2023 - showing only the latest 10 entries)
----
f486fbb Write report section on API
fd01200 Add report section on data dashboard
23f52ea Detail project scope in a new file
60f996d Fix typo in schema name in report
d1433c4 Use argon2 for password hashing instead of scrypt
7bc8485 Create some documentation on the demo run
c668c8e [chore] Bump to 0.3.0
43d15ad Add bump_version command
59b0511 Extend project compatibility to Python >= 3.9 instead of 3.11
515d93d Rename pdm.Dockerfile simply to "Dockerfile"
----

The software itself is written using sensible practices : clear and consistent naming, short and readable functions, type annotations, consistent formatting (using `black`),â€¦ Following the principle that the best documentation is no documentation (since documentation and code quickly get out-of-sync), code was written with readability as a primary concern. Documentation was only added in places which do not read well enough or feature non-obvious design choices, or to serve as documentation of external features that are not very well-documented.

[#hour-break-dash-comment]
.Documenting hard-coded values
[,python]
// This should display the long comment about "hour-break"
----
include::../src/opa/data_report.py[lines=70..86]
----

GitHub actionsfootnote:[https://github.com/DataScientest-Studio/juin23_bde_opa/actions] have been leveraged to provide _Continuous Integration_, e.g. by ensuring that the code is properly formatted or that unit tests keep on passing.

.GitHub badges
image::github_badges.png[]


=== Packaging the project

Packaging is the process by which a piece of software is prepared for distribution and installation in its runtime environment (which is usually distinct from the environment in which it is developed). In Python, it is a well-known headachefootnote:[https://chriswarrick.com/blog/2023/01/15/how-to-improve-python-packaging/#does-python-really-need-virtual-environments], with no established ubiquitous tool nor clear, universal instructions.

Of the numerous options available : pip + venv + setuptools, Hatchfootnote:[https://hatch.pypa.io/], Poetryfootnote:[https://python-poetry.org/], pipenvfootnote:[https://pipenv.pypa.io/], PDMfootnote:[https://pdm.fming.dev/],.. I have elected to go for the latter, which works basically like `npm` does in the Node-JS ecosystem. Simple commands allow to init a skeleton project, add production or development dependencies, build the project for distribution, install it, and so on.

Runtime configuration (e.g. HTTP ports used, database configuration, ...) is handled by Dynaconffootnote:[https://www.dynaconf.com/], which can read configuration either from a file or from environment variables. The secrets required to run the project (API keys, database credentials, ...) are merged into the configuration at startup.

With a properly packaged project, any machine that can run Python can now install and run it. The helper script `run_local.sh` allows to start any of the 3 parts of the project on the local machine, a feature which has proven extremely useful in the development phase (where running a full Docker image is much heavier and slow). An interactive shell (that uses IPython) was even added to allow "playing" with the internal APIs in the same environment as the running application.


=== Orchestrating the project

Though it would be possible to manually launch the 3 different parts of the project in different processes of the same machine, it is not necessarily super practical.

For this reason, both Docker and Docker Compose have been leveraged to allow running the whole project in a consistent way.

The `Dockerfile` has been written with inspiration from the Dockerfile suggested on PDM websitefootnote:[https://pdm.fming.dev/latest/usage/advanced/#use-pdm-in-a-multi-stage-dockerfile], with some modifications to ensure dependencies are not installed on every source code modification.

The `docker-compose.yml` file is quite straightforward, making use of Docker Compose features such as volumesfootnote:[https://docs.docker.com/compose/compose-file/07-volumes/] or secretsfootnote:[https://docs.docker.com/compose/compose-file/09-secrets/]. It defines all the services that make up the application :

* external images : `database` which is simply an official `mongo` imagefootnote:[https://hub.docker.com/_/mongo], properly setup
* internal images : `financial_data_reader`, `data_report`, `internal_api`
* test images : to allow running unit, integration, or functional tests
